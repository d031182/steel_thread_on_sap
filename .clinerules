# Development Standards & Best Practices

**Version**: 4.2  
**Last Updated**: 2026-02-22 (Project Tracker Standardization + Auto-Increment Task Naming)
**Purpose**: Core standards for P2P Data Products development

---

## âš ï¸ CRITICAL: GU WU API CONTRACT TESTING FOUNDATION

**CORE PRINCIPLE**: Test API contracts, not implementation details â­ FUNDAMENTAL

### The Breakthrough Insight (Feb 15, 2026)

> "The foundation of Gu Wu is to test the backend APIs and frontend APIs. 
> By testing consistently this API contract, you test implicitly all other 
> contributing functions without testing them explicitly."

**What This Means**:
- âœ… Test **Backend APIs**: Business logic endpoints (`/api/ai-assistant/chat`, `/api/data-products`)
- âœ… Test **Frontend APIs**: Metadata/configuration endpoints (`/api/modules/frontend-registry`)
- âœ… **ONE API test validates entire chain**: Controller â†’ Service â†’ Repository â†’ Database
- âŒ DON'T test every internal function explicitly (maintenance burden)
- âœ… DO trust implementation, test the public contract

**Why This Works**:
- **EFFICIENCY**: One API contract test exercises entire call stack implicitly
- **SPEED**: 60-300x faster than browser testing (< 1 second vs 60-300 seconds)
- **IMPLICIT COVERAGE**: API test automatically validates all contributing functions
- **EXAMPLE**: `POST /api/ai-assistant/chat` tests AgentService, ConversationRepository, Database implicitly

**Test Pyramid** (API-Focused):
```
10% E2E Tests         - Critical user workflows
20% Integration       - API contract tests â­ FOCUS HERE
70% Unit Tests        - Only for complex algorithms/utilities
```

**MANDATORY TESTING WORKFLOW**:

1. **Design API Contracts** (BEFORE implementation):
   - Define endpoints (method, path, purpose)
   - Define request/response schemas
   - Write contract tests with `@pytest.mark.api_contract`

2. **Implement APIs**:
   - Backend API (business logic)
   - Frontend API (metadata/configuration)
   
3. **Test APIs via requests** (< 1 second):
   ```python
   @pytest.mark.e2e
   @pytest.mark.api_contract
   def test_endpoint_contract():
       """Test: API returns valid contract structure"""
       response = requests.post(url, json=payload)
       assert response.status_code == 200
       assert 'success' in response.json()
   ```

4. **Verify APIs stable** (all contract tests passing)

5. **THEN build UX** (on stable API foundation)

**AI Enforcement** (MANDATORY):

Before implementing ANY feature, AI must ask in `<thinking>`:
1. â“ Have I designed the API endpoints?
2. â“ Have I written API contract tests?
3. â“ Have I tested APIs via requests/curl (< 1s)?
4. â“ Are all API contract tests passing?
5. â“ Am I about to build UX without stable APIs?

**If APIs not tested/stable**: STOP. Test APIs FIRST.

---

## ğŸ¯ PRIORITY 0: WINDOWS COMMAND COMPATIBILITY âš ï¸ MANDATORY

### 0. Windows-Compatible Commands (No Unix Assumptions)

**RULE**: Never assume Unix commands available on Windows. The system uses Windows 11 with cmd.exe.

**COMMON UNIX COMMANDS NOT AVAILABLE IN WINDOWS CMD**:
- âŒ `head` (show first N lines)
- âŒ `tail` (show last N lines)
- âŒ `grep` (pattern matching)
- âŒ `sed` (stream editor)
- âŒ `awk` (text processing)
- âŒ `cat` (concatenate files)
- âŒ `wc` (word count)

**WINDOWS ALTERNATIVES**:

| Unix Command | Windows PowerShell Alternative | Windows CMD Alternative |
|---|---|---|
| `head -n 10 file.txt` | `Get-Content file.txt -Head 10` (alias: `gc file.txt -Head 10`) | `powershell -Command "gc file.txt -Head 10"` |
| `tail -n 10 file.txt` | `Get-Content file.txt -Tail 10` | `powershell -Command "gc file.txt -Tail 10"` |
| `grep "pattern" file.txt` | `Select-String "pattern" file.txt` | `findstr "pattern" file.txt` |
| `cat file.txt` | `Get-Content file.txt` | `type file.txt` |
| `wc -l file.txt` | `(Get-Content file.txt \| Measure-Object -Line).Lines` | Use PowerShell |

**PREFERRED APPROACH** (Cross-Platform):

1. âœ… **Use Python for text processing** (works everywhere):
   ```python
   # Instead of: head -n 10 file.txt
   with open('file.txt') as f:
       for i, line in enumerate(f):
           if i >= 10:
               break
           print(line.rstrip())
   ```

2. âœ… **Use PowerShell for scripting**:
   ```powershell
   # Show first 10 lines
   Get-Content file.txt -Head 10
   
   # Show last 10 lines
   Get-Content file.txt -Tail 10
   
   # Pattern matching
   Select-String "pattern" file.txt
   ```

3. âœ… **Call PowerShell from Python**:
   ```python
   import subprocess
   result = subprocess.run(
       ['powershell', '-Command', 'Get-Content file.txt -Head 10'],
       capture_output=True, text=True
   )
   print(result.stdout)
   ```

**AI ENFORCEMENT** (CRITICAL):

Before executing ANY command with `execute_command`, AI must ask in `<thinking>`:
1. â“ Does this command use Unix-only tools (head, tail, grep, sed, awk, cat, wc)?
2. â“ Is the system running Windows (check: `Operating System: Windows 11`)?
3. â“ Have I replaced Unix commands with Windows equivalents?
4. â“ If unsure, use Python or PowerShell for cross-platform compatibility?

**If using Unix commands on Windows**: STOP. Use Windows/PowerShell alternatives.

---

## ğŸ¯ PRIORITY 1: SAFETY CHECKPOINT

### 1. Clean Git State Before Critical Changes âš ï¸ MANDATORY

**RULE**: Before any risky operation, ensure clean git state with remote backup

**Critical Operations**:
- âœ… Architecture refactoring
- âœ… Database schema changes
- âœ… Build system changes
- âœ… Multi-file operations

**Safety Workflow**:
```bash
git status
git add .
git commit -m "checkpoint: [state]"
git push origin main
# Now safe to proceed
```

---

## ğŸ¯ PRIORITY 1: ESSENTIAL WORKFLOWS

### 1. Knowledge Graph First â­ MANDATORY

**Before ANY work**:
```xml
<use_mcp_tool>
  <server_name>github.com/modelcontextprotocol/servers/tree/main/src/memory</server_name>
  <tool_name>search_nodes</tool_name>
  <arguments>{"query": "[terms]"}</arguments>
</use_mcp_tool>
```

**At session end**: Store learnings with complete WHY context (8 elements: WHAT, WHY, PROBLEM, ALTERNATIVES, CONSTRAINTS, VALIDATION, WARNINGS, CONTEXT)

---

### 2. Knowledge Vault Documentation â­ MANDATORY

**ALL docs â†’ `docs/knowledge/` vault**
- âœ… Use [[wikilinks]] for cross-references
- âœ… Update `INDEX.md` with every doc
- âŒ No .md files outside vault (except .clinerules, PROJECT_TRACKER.md, README.md)

---

### 3. API-First Development â­ MANDATORY

**Order** (NO EXCEPTIONS):
1. âœ… Design API contracts (backend + frontend)
2. âœ… Write API contract tests (`@pytest.mark.api_contract`)
3. âœ… Implement APIs
4. âœ… **TEST APIs via curl/requests** (< 1 second) â­ CRITICAL
5. âœ… Verify all API tests passing
6. âœ… THEN build UX on stable foundation

**Why**:
- API bugs found during UX = rework both layers
- API testing 60-300x faster than browser testing
- Stable APIs = UX focuses on experience only

---

## ğŸ¯ PRIORITY 2: TESTING STANDARDS

### 4. Test File Organization â­ MANDATORY

**RULE**: ALL test files MUST be organized by module in `/tests/[module]/` subdirectories

**Structure**:
```
tests/
â”œâ”€â”€ ai_assistant/                     # AI Assistant module tests
â”‚   â”œâ”€â”€ test_ai_assistant_adapter.py
â”‚   â”œâ”€â”€ test_ai_assistant_backend.py
â”‚   â”œâ”€â”€ test_ai_assistant_frontend_api.py
â”‚   â”œâ”€â”€ test_ai_assistant_hana_context.py
â”‚   â”œâ”€â”€ test_ai_assistant_hana_e2e.py
â”‚   â”œâ”€â”€ test_ai_assistant_hana_frontend.py
â”‚   â”œâ”€â”€ test_ai_assistant_datasource_eventbus.py
â”‚   â””â”€â”€ test_ai_assistant_invoice_count_hana.py
â”œâ”€â”€ data_products_v2/                 # Data Products V2 module tests
â”‚   â”œâ”€â”€ test_data_products_v2_backend.py
â”‚   â””â”€â”€ test_data_products_v2_frontend_api.py
â”œâ”€â”€ log/                              # Log module tests
â”‚   â”œâ”€â”€ test_log_backend.py
â”‚   â””â”€â”€ test_log_frontend_api.py
â”œâ”€â”€ integration/                      # Integration tests (SAP AI Core, Pydantic AI)
â”‚   â”œâ”€â”€ test_ai_core_setup.py
â”‚   â”œâ”€â”€ test_advanced_pydantic_ai_headers.py
â”‚   â”œâ”€â”€ test_pydantic_ai_chat_api.py
â”‚   â””â”€â”€ test_pydantic_ai_sap_ai_core.py
â”œâ”€â”€ debug/                            # Debug/experimental tests
â”‚   â”œâ”€â”€ test_ai_chat_debug.py
â”‚   â”œâ”€â”€ test_conversation_context_debug.py
â”‚   â””â”€â”€ test_fengshui_v49.py
â”œâ”€â”€ unit/                             # Unit tests (e.g., tools/fengshui)
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ fengshui/
â”‚           â””â”€â”€ test_module_federation_agent.py
â”œâ”€â”€ test_smoke.py                     # Smoke tests (top-level)
â”œâ”€â”€ conftest.py                       # Shared fixtures
â””â”€â”€ README.md                         # Test documentation
```

**FORBIDDEN**:
- âŒ Creating test files in root directory (e.g., `test_*.py` in root)
- âŒ Creating test files in module directories
- âŒ Mixing unrelated tests in same subdirectory
- âœ… ALWAYS create in `/tests/[module]/` subdirectory

**AI Enforcement**:
Before creating ANY test file, AI must ask in `<thinking>`:
1. â“ Which module does this test belong to? (ai_assistant, data_products_v2, log, etc.)
2. â“ Is this an integration test? (â†’ tests/integration/)
3. â“ Is this a debug/experimental test? (â†’ tests/debug/)
4. â“ Is the path `/tests/[appropriate_subdirectory]/test_*.py`?

**If test file not in correct subdirectory**: STOP. Place in `/tests/[module]/` directory.

**Running Tests by Module**:
```bash
pytest tests/ai_assistant/ -v          # Run AI Assistant tests only
pytest tests/data_products_v2/ -v      # Run Data Products tests only
pytest tests/integration/ -v           # Run integration tests only
pytest tests/ -v                       # Run all tests
```

---

### 5. Gu Wu API Contract Testing â­ CORE METHODOLOGY

**Philosophy**: "Test the contract, trust the implementation"

**What to Test** (API Contracts ONLY):

**âœ… REQUIRED - API Contract Tests**:
```python
@pytest.mark.e2e
@pytest.mark.api_contract
def test_backend_api_contract():
    """Test: Backend API returns valid contract"""
    # ARRANGE
    url = "http://localhost:5000/api/[module]/[endpoint]"
    
    # ACT
    response = requests.post(url, json=payload, timeout=5)
    
    # ASSERT
    assert response.status_code == 200
    assert 'success' in response.json()
    assert 'data' in response.json()

@pytest.mark.e2e
@pytest.mark.api_contract
def test_frontend_api_contract():
    """Test: Frontend API returns metadata"""
    # ARRANGE
    url = "http://localhost:5000/api/modules/frontend-registry"
    
    # ACT
    response = requests.get(url, timeout=5)
    
    # ASSERT
    data = response.json()
    assert 'modules' in data
    assert len(data['modules']) > 0
```

**âŒ NOT REQUIRED - Internal Function Tests**:
- âŒ Don't test `service.method()` explicitly (tested implicitly via API)
- âŒ Don't test `repository.query()` explicitly (tested implicitly via API)
- âŒ Don't test `database.execute()` explicitly (tested implicitly via API)
- âœ… DO test complex algorithms/utilities IF used outside API chain

**Why This Works**:
- One API test validates entire call chain automatically
- Internal refactoring doesn't break tests (only contracts matter)
- Maintenance burden reduced dramatically
- Tests stay green as long as API contract honored

**Test Structure**:
```
tests/
â”œâ”€â”€ test_[module]_backend_api.py      # Backend API contracts
â”œâ”€â”€ test_[module]_frontend_api.py     # Frontend API contracts
â”œâ”€â”€ test_smoke.py                      # Module import validation
â””â”€â”€ conftest.py                        # Shared fixtures
```

**AI Enforcement** (MANDATORY):

Before using `attempt_completion`, AI must ask in `<thinking>`:
1. â“ Have I written API contract tests?
2. â“ Have I run API tests via requests (< 1s)?
3. â“ Are all API contract tests passing?
4. â“ Am I testing implementation details unnecessarily?

**If testing internal functions**: Ask yourself: "Is this tested implicitly via API contract?"

---

### 5. Test Verification Protocol âš ï¸ CRITICAL

**MANDATORY SEQUENCE**:
1. âœ… Write API contract tests
2. âœ… Run: `pytest [test_file] -v`
3. âœ… WAIT for completion
4. âœ… Verify all green
5. âœ… THEN use `attempt_completion`

**FORBIDDEN**:
- âŒ Write tests â†’ attempt_completion (without running)
- âŒ Tests fail â†’ attempt_completion anyway

---

### 6. Browser Testing: AVOID âš ï¸

**RULE**: Use `browser_action` ONLY as last resort

**Correct Methods** (Try FIRST):
1. â­ **API Contract Testing**: `requests.get/post()` (< 1 second)
2. â­ **pytest**: Automated, fast, reliable
3. âŒ **Browser**: Only for final UX validation (after APIs stable)

**Key Insight**:
> Every UI activity maps to API call. Test the API first!

---

## ğŸ¯ PRIORITY 2.5: AUTO-INCREMENT TASK NAMING STANDARD

### Auto-Increment Task ID Convention â­ NEW STANDARD

**Purpose**: When a completed task generates phased implementation work, use `t-XXX` naming for auto-increment tasks

**Pattern**:
- Format: `t-001`, `t-002`, `t-003`, etc. (no leading zeros for single/double digits is fine, use 3-digit format for clarity)
- Storage: MEDIUM priority section in PROJECT_TRACKER.md
- Lifecycle: Auto-increment tasks until all are complete, then all removed together
- Documentation: Each t-xxx task clearly states dependencies and effort

**When to Create Auto-Increment Tasks**:
- âœ… When a completed task analysis reveals phased implementation work
- âœ… When work is divided into sequential, related subtasks
- âœ… When individual tasks would clutter PROJECT_TRACKER but are interconnected
- âŒ NOT for unrelated work (those get regular HIGH/MED/LOW task IDs)

**Example** (from HIGH-43.3):
```
| t-001 | Replace Spacing Magic Numbers... | 3-4 hours | PLANNED | | HIGH-43.3 âœ… |
| t-002 | Replace Sizing Magic Numbers...  | 3-4 hours | PLANNED | | t-001 |
| t-003 | Replace Timing Magic Numbers...  | 1-2 hours | PLANNED | | t-002 |
| t-004 | Create CSS Validation Tests...   | 2-3 hours | PLANNED | | t-003 |
| t-005 | Implement Pre-Commit CSS...      | 1-2 hours | PLANNED | | t-004 |
```

**Lifecycle Management**:
1. **Creation**: When parent task (HIGH-43.3) completes, create t-001 through t-005 as auto-increment block
2. **Duration**: Auto-increment tasks stay in PROJECT_TRACKER until ALL are complete (not individual removal)
3. **Completion**: When all t-xxx tasks complete, entire block removed to VERSION HISTORY (not individual removals)
4. **Documentation**: Link t-xxx tasks back to parent task (e.g., `| t-001 | ... | | HIGH-43.3 âœ… |`)

**Benefits**:
- **Clarity**: Phased work organized together vs scattered HIGH/MED tasks
- **Dependency Tracking**: Clear sequential dependencies (t-001 â†’ t-002 â†’ t-003)
- **Bulk Removal**: All related tasks removed together when complete (cleaner tracker)
- **Self-Contained**: Auto-increment series clearly tied to parent analysis task

**AI Enforcement**:
Before creating new tasks in PROJECT_TRACKER, AI must ask in `<thinking>`:
1. â“ Is this standalone work? (â†’ Use HIGH/MED/LOW/LOW task ID)
2. â“ Is this phased implementation from a completed task? (â†’ Use t-xxx auto-increment)
3. â“ Does this have clear sequential dependencies? (â†’ Use t-xxx auto-increment)
4. â“ Will these tasks be completed together? (â†’ Use t-xxx auto-increment for bulk removal)

---

## ğŸ¯ PRIORITY 3: ARCHITECTURE & QUALITY

### 7. Feng Shui - Architecture Intelligence

**When to Use**:
```bash
# Comprehensive multi-agent analysis
python -m tools.fengshui analyze

# Autonomous batch fixes
python -m tools.fengshui fix

# Module quality gate
python -m tools.fengshui gate --module [name]
```

**Let Feng Shui handle** architecture repairs autonomously

---

### 8. Shi Fu - Quality Ecosystem

**Session Start Routine**:
```bash
python -m tools.shifu --session-start
```

Automatically checks ecosystem health, updates PROJECT_TRACKER.md with priorities

---

### 9. Modular Architecture â­ FOLLOW MODULE FEDERATION STANDARD

**MANDATORY**: Follow [[Module Federation Standard]] v1.0 for ALL modules

**Module Isolation** (CRITICAL): Modules MUST NEVER import from each other
- âœ… Use `core/interfaces/` with Dependency Injection
- âŒ NEVER `from modules.other_module import ...` (9th Feng Shui agent detects violations)
- âœ… Enforcement: Feng Shui Module Isolation Agent (0 violations verified)
- ğŸ“– See [[Module Isolation Enforcement Standard]] (600+ lines, multi-layer defense)

**Module Structure** (from standard):
```
modules/[name]/
â”œâ”€â”€ module.json         # â­ Single source of truth (REQUIRED)
â”œâ”€â”€ README.md           # Documentation (REQUIRED)
â”œâ”€â”€ backend/            # Flask Blueprint, Service, Repository
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py          # Flask Blueprint (REQUIRED)
â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â””â”€â”€ repositories/   # Data access
â”œâ”€â”€ frontend/           # Bootstrap, Adapter, View
â”‚   â”œâ”€â”€ module.js       # Factory (REQUIRED)
â”‚   â”œâ”€â”€ adapters/       # API client
â”‚   â””â”€â”€ views/          # UI components
â””â”€â”€ tests/              # API contracts (REQUIRED)
    â”œâ”€â”€ test_backend_api.py
    â””â”€â”€ test_frontend_api.py
```

**Naming Conventions** (MANDATORY):
- Module IDs: `snake_case` (e.g., `ai_assistant`)
- Routes: `/kebab-case` (e.g., `/ai-assistant`)
- API Paths: `/api/kebab-case` (e.g., `/api/ai-assistant`)
- Factories: `PascalCase` + `Module` (e.g., `AIAssistantModule`)

**Quality Gates**:
- Feng Shui validation (structure, naming, patterns)
- API contract tests (backend + frontend)
- 70%+ test coverage
- Documentation complete

**Reference**: `docs/knowledge/module-federation-standard.md` (950+ lines)

**Validation**: Feng Shui quality gate

---

## ğŸ¯ PRIORITY 4: OPERATIONAL

### 10. Server Cleanup âš ï¸ MANDATORY

**Before `attempt_completion`**:
```bash
taskkill /F /IM python.exe  # Kill test servers
```

**NEVER** start servers via `<command>` in attempt_completion

---

### 11. Git Workflow

**AI Can Execute Git** ONLY when user explicitly requests:
- âœ… User says "git push with tag" â†’ AI executes
- âœ… Otherwise: AI stages, user commits/pushes

**Tag Handling**:
- âœ… If tag exists, increment version
- âŒ NEVER delete/force-push tags

---

### 12. Project Tracker â­ MANDATORY CLEANUP RULE

**PROJECT_TRACKER.md** (~150 lines):
- QUICK START (API-First workflow, key commands, documentation links)
- ACTIVE TASKS (CRITICAL, HIGH, MEDIUM, LOW priorities - only ongoing/planned work)
- VERSION HISTORY (completed phases with learnings preserved in git tags)

**Structure** (MANDATORY):
```
## ğŸš€ QUICK START
- Development workflow (7 steps)
- Key commands (pytest, Feng Shui, Shi Fu)
- Documentation references

## ğŸ“‹ ACTIVE TASKS
### ğŸ”´ CRITICAL (Production Blockers)
| ID | Priority | Task | Effort | Status | Completed Date | Notes |

### ğŸŸ  HIGH (Quality & Architecture)
| ID | Priority | Task | Effort | Status | Completed Date | Notes |

### ğŸŸ¢ MEDIUM (Features & Enhancements)
| ID | Task | Effort | Status | Completed Date | Dependencies | Notes |

### ğŸ”µ LOW (Nice to Have)
| ID | Priority | Task | Effort | Status | Completed Date | Notes |

## ğŸ“š VERSION HISTORY
### v4.2 (date) - [title]
**Completed**: [list of accomplishments]
**Key Learnings**: [8 elements: WHAT, WHY, PROBLEM, ALTERNATIVES, CONSTRAINTS, VALIDATION, WARNINGS, CONTEXT]

### Earlier Versions
[Archived references]
```

**Column Standards** (MANDATORY):
- âœ… All ACTIVE TASKS tables use consistent columns: ID, Priority, Task, Effort, Status, Completed Date, Notes
- âœ… MEDIUM table includes Dependencies column before Notes for linking related tasks
- âœ… No variation in final column naming (always "Notes", not "Recommendation")
- âœ… Completed Date field present in all priority levels for 7-day tracking

**Completed Date Field** (MANDATORY):
- âœ… Track date when task was marked complete (YYYY-MM-DD format)
- âœ… Calculate 7-day window from completion date
- âœ… Remove task from ACTIVE TASKS when: `today - completed_date >= 7 days`
- âœ… Move task to VERSION HISTORY with completion date reference
- âŒ NEVER remove tasks before 7 days have passed

**CRITICAL RULE - Remove Completed Tasks**:
- âœ… **WHEN TASK COMPLETE (7 days)**: Remove from "ACTIVE TASKS" table 7 days after completion
- âœ… Move detailed implementation notes to "VERSION HISTORY" section under appropriate version tag
- âœ… This keeps tracker lean (only active/planned work visible)
- âœ… Historical context preserved in VERSION HISTORY + git tags
- âŒ NEVER leave completed tasks in ACTIVE TASKS table beyond 7 days
- âœ… AI must proactively remove tasks when marking complete + 7 days
- âœ… Update tracker header: `**Last Updated**: YYYY-MM-DD (Brief description of latest update)`

**Tracker Maintenance**:
1. After each session: Update date and brief description in header
2. Before git commit: Verify no completed tasks in ACTIVE TASKS
3. Move task details to VERSION HISTORY: Include learnings in 8-element format
4. Git tags: Store comprehensive work package details (reference via `git show v[version]`)

---

## ğŸ“‹ AI CHECKLIST (UPDATED FOR API-FIRST)

**Before implementing**:
1. âœ… Check knowledge graph
2. âœ… Check architecture discussed (implement first if 60+ min discussion)
3. âœ… **Design API contracts** (backend + frontend) â­
4. âœ… **Write API contract tests** â­
5. âœ… Implement APIs
6. âœ… **Test APIs via requests** (< 1s) â­
7. âœ… Verify API tests passing â­
8. âœ… THEN build UX
9. âœ… Update PROJECT_TRACKER.md (move completed to VERSION HISTORY)

**Before attempt_completion**:
1. âœ… Task completed and verified
2. âœ… Remove completed tasks from ACTIVE TASKS
3. âœ… Add VERSION HISTORY entry with learnings (8 elements)
4. âœ… Update tracker header date and description
5. âœ… Server cleanup: `taskkill /F /IM python.exe`
6. âœ… Git checkpoint: `git add . && git commit && git push`

**NO SHORTCUTS**: Test APIs first, build UX second

---

## ğŸ“ Quick Reference

### Testing Philosophy â­ CORE
**"Test the contract, trust the implementation"**
- Backend APIs: `/api/[module]/[endpoint]`
- Frontend APIs: `/api/modules/frontend-registry`
- One API test = entire call chain validated
- 60-300x faster than browser testing

### Tools
- **Feng Shui**: Architecture quality - 7 agents (`python -m tools.fengshui analyze`)
  - Architecture, Security, UX, FileOrg, Performance, Documentation, TestCoverage
- **Gu Wu**: API contract tests (`pytest tests/ -m api_contract`)
- **Shi Fu**: Ecosystem insights (`python -m tools.shifu --session-start`)

### Key Docs
- [[Module Federation Standard]] - â­ Official module architecture (module.json, naming, patterns)
- `docs/knowledge/INDEX.md` - All documentation
- [[Gu Wu API Contract Testing Foundation]] - Core methodology
- [[API-First Contract Testing Methodology]] - Complete guide

---

**Summary**: 
1. **Priority 0**: Git checkpoint before critical changes
2. **Priority 1**: Knowledge graph, docs, API-first design
3. **Priority 2**: API contract testing (backend + frontend)
4. **Priority 2.5**: Auto-increment task naming standard (t-001, t-002, etc.) â­ NEW
5. **Priority 3**: Architecture (Feng Shui), Quality (Shi Fu)
6. **Priority 4**: Server cleanup, git workflow

**CORE INSIGHT (v4.2)**: Test API contracts consistently â†’ All contributing functions tested implicitly. This is the foundation of Gu Wu. Auto-increment tasks (t-xxx) organize phased implementation work from completed analysis tasks.