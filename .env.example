# ============================================================================
# AI Provider Configuration
# ============================================================================
# Choose your LLM provider: "litellm" | "groq" | "github" | "ai_core"
# Default: litellm (OpenAI-compatible proxy for multiple models)
AI_PROVIDER=litellm

# ============================================================================
# OPTION 1: LiteLLM (Recommended - Default)
# ============================================================================
# OpenAI-compatible proxy for multiple LLM providers (OpenAI, Anthropic, etc.)
# Supports model routing, load balancing, and cost tracking
# Setup: Run LiteLLM proxy server locally or use hosted version
LITELLM_BASE_URL=http://localhost:6655/litellm/v1
LITELLM_API_KEY=4930f138-112d-4d69-bf98-77a7e5dbebc5
LITELLM_MODEL_NAME=gpt-4.1-mini

# ============================================================================
# OPTION 2: Groq (Ultra-Fast Alternative)
# ============================================================================
# Ultra-fast inference via LPU architecture
# Models: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
# Get key from: https://console.groq.com
# GROQ_API_KEY=your_groq_api_key_here

# ============================================================================
# OPTION 3: GitHub Models (OpenAI GPT-4o-mini)
# ============================================================================
# Access GPT-4o-mini via GitHub's inference endpoint
# Get token from: https://github.com/settings/tokens
# GITHUB_TOKEN=your_github_personal_access_token_here
# GITHUB_MODEL_NAME=gpt-4o-mini  # Optional, default: gpt-4o-mini

# ============================================================================
# OPTION 4: SAP AI Core (Enterprise)
# ============================================================================
# Enterprise-grade LLM access via Azure OpenAI
# AI_CORE_CLIENT_ID=your_client_id
# AI_CORE_CLIENT_SECRET=your_client_secret
# AI_CORE_DEPLOYMENT_URL=https://api.ai.your-region.cloud.sap/v2/inference/deployments/your-deployment-id/chat/completions
# AI_CORE_RESOURCE_GROUP=default
# AI_CORE_MODEL_NAME=gpt-4o-mini

# ============================================================================
# Database Configuration
# ============================================================================
# SQLite (default for local development)
DATA_SOURCE=sqlite
SQLITE_DB_PATH=./database/p2p_data.db

# HANA Cloud (for production)
# DATA_SOURCE=hana
# HANA_HOST=your-hana-instance.hana.prod.region.hanacloud.ondemand.com
# HANA_PORT=443
# HANA_USER=your_username
# HANA_PASSWORD=your_password
# HANA_DATABASE=P2P
# HANA_ENCRYPT=true