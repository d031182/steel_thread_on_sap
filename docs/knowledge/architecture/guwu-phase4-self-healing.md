# Gu Wu Phase 4: Self-Healing & Autonomous Test Generation

**Status**: Design Phase  
**Priority**: HIGH  
**Philosophy**: "Gu Wu learns from production failures and automatically generates missing tests"

---

## Vision

When a bug occurs in production (like the cache refresh bug), Gu Wu should:
1. **Detect** the failure pattern automatically
2. **Analyze** what test was missing that would have caught it
3. **Generate** the missing test automatically
4. **Alert** the developer with the test ready to commit
5. **Learn** to prevent similar gaps in future

---

## Current Situation (Phase 3)

**What We Have**:
- âœ… Gap Analyzer: Finds missing tests based on static code analysis
- âœ… Predictor: Predicts likely failures
- âœ… Lifecycle: Tracks test health
- âœ… Reflection: Learns patterns
- âœ… Redundancy: Finds duplicates

**What's Missing**:
- âŒ No awareness of production failures
- âŒ Cannot correlate bugs to missing tests
- âŒ Cannot auto-generate tests
- âŒ Reactive (finds gaps) not proactive (prevents bugs)

---

## The Cache Refresh Bug Example

**What Happened**:
1. Modified `knowledge_graph_facade.py` to call `cache_service.clear_cache()`
2. But `clear_cache()` required `graph_type` parameter
3. **Missing Test**: No integration test for facade â†’ cache_service interaction
4. Bug shipped to production
5. User discovered manually

**What Gu Wu Phase 4 Would Do**:
1. **Detect Failure**: Monitor application logs for exceptions
2. **Analyze Stack Trace**: `facade.refresh_ontology_cache()` â†’ `cache_service.clear_cache()` â†’ TypeError
3. **Identify Gap**: "No integration test covers this method call chain"
4. **Generate Test**:
   ```python
   # AUTO-GENERATED BY GU WU - 2026-02-05
   # Reason: Production bug detected in facade.refresh_ontology_cache()
   
   @pytest.mark.integration
   def test_refresh_ontology_cache_integration():
       """
       Integration test: Verify facade correctly calls cache service.
       
       This test was auto-generated because a production bug occurred
       where facade called clear_cache() with wrong signature.
       """
       # ARRANGE
       facade = KnowledgeGraphFacade()
       
       # ACT
       result = facade.refresh_ontology_cache()
       
       # ASSERT
       assert result['status'] == 'success'
       assert 'deleted_records' in result
   ```
5. **Alert Developer**: "ðŸš¨ Gu Wu detected production bug - generated missing test"
6. **Learn**: "Always check method signatures in integration tests for facade â†’ service calls"

---

## Phase 4 Architecture

### 1. Production Monitoring Integration

**Log Watchers**:
- Monitor `app/logs/` for exceptions
- Monitor application error handlers
- Monitor frontend error logger (`clientErrorLogger.js`)

**Failure Pattern Detection**:
```python
class FailurePatternDetector:
    def analyze_exception(self, exception_data):
        """
        Analyze production exception and determine:
        1. What code path failed
        2. What test would have caught it
        3. What layer test is needed (unit/integration/e2e)
        """
        stack_trace = exception_data['stack_trace']
        error_type = exception_data['error_type']
        
        # Analyze call chain
        call_chain = self._parse_stack_trace(stack_trace)
        
        # Determine missing test
        missing_test = self._identify_gap(call_chain, error_type)
        
        return missing_test
```

### 2. Intelligent Test Generation

**Test Generator**:
```python
class TestGenerator:
    def generate_test(self, failure_pattern):
        """
        Auto-generate test based on failure pattern.
        
        Uses:
        - Code analysis (AST parsing)
        - Existing test patterns (learns from codebase)
        - OpenAI/Claude API for intelligent generation
        """
        # Analyze code structure
        code_structure = self._analyze_code(failure_pattern.file_path)
        
        # Find similar existing tests
        similar_tests = self._find_similar_tests(code_structure)
        
        # Generate test using pattern learning
        test_code = self._generate_test_code(
            failure_pattern,
            code_structure,
            similar_tests
        )
        
        return test_code
```

### 3. Confidence Scoring

**Before Auto-Committing**:
- Gu Wu calculates confidence score (0.0-1.0)
- High confidence (>0.8): Auto-create test, alert developer
- Medium confidence (0.5-0.8): Create draft, ask for review
- Low confidence (<0.5): Alert developer, suggest manual test

### 4. Learning Loop

**After Each Bug**:
1. Store failure pattern in `tools/guwu/failures.db`
2. Link to generated test
3. Track if test actually catches bug
4. Refine generation algorithm based on success rate

---

## Implementation Phases

### Phase 4.1: Log Monitoring (Week 1)
- [x] Application logs exist (`app/logs/`)
- [ ] Create log watcher (`tools/guwu/log_watcher.py`)
- [ ] Parse exception patterns
- [ ] Store in failures database

### Phase 4.2: Gap Correlation (Week 2)
- [ ] Analyze stack traces
- [ ] Map to missing tests
- [ ] Calculate confidence scores

### Phase 4.3: Test Generation (Week 3)
- [ ] Create test generator
- [ ] Use existing tests as templates
- [ ] Generate pytest-compliant code

### Phase 4.4: Integration (Week 4)
- [ ] Hook into pytest finish
- [ ] Auto-generate on test run
- [ ] Alert developer via terminal

### Phase 4.5: Self-Learning (Week 5)
- [ ] Track generation accuracy
- [ ] Refine algorithms
- [ ] Build pattern library

---

## User Experience

### Scenario: Bug Occurs

**Step 1: Bug Happens**
```
User clicks "Refresh Graph" â†’ Error in logs
```

**Step 2: Next Test Run**
```bash
$ pytest

[Gu Wu] Detected 1 production failure since last run
[Gu Wu] Analyzing failure pattern...
[Gu Wu] Generated missing integration test: tests/integration/test_graph_cache_refresh_sync.py
[Gu Wu] Confidence: 85% - Review recommended

ðŸš¨ CRITICAL: Production Bug Detected
   File: modules/knowledge_graph/backend/knowledge_graph_facade.py
   Error: TypeError - clear_cache() missing required argument
   
   âœ… Auto-generated test: tests/integration/test_graph_cache_refresh_sync.py
   
   Next steps:
   1. Review generated test
   2. Run: pytest tests/integration/test_graph_cache_refresh_sync.py
   3. Commit if test passes
```

**Step 3: Developer Reviews**
- Generated test appears in `tests/integration/`
- Developer reviews, tweaks if needed
- Commits test with bug fix

**Step 4: Gu Wu Learns**
- Tracks if test actually catches bug
- Improves generation for similar patterns
- Never makes same gap again

---

## Technical Requirements

### Dependencies
- `ast`: Python code analysis
- `radon`: Complexity metrics
- `jedi`: Code intelligence
- `openai` or `anthropic`: AI generation (optional, fallback to templates)

### Storage
```
tools/guwu/
â”œâ”€â”€ failures.db          # Production failure tracking
â”œâ”€â”€ patterns.db          # Learned failure patterns
â”œâ”€â”€ generated_tests/     # Staged tests (pending review)
â””â”€â”€ learning_metrics.db  # Generation accuracy tracking
```

### Configuration
```python
# pytest.ini or tools/guwu/config.py
GUWU_PHASE4_ENABLED = True
GUWU_AUTO_GENERATE_TESTS = True
GUWU_CONFIDENCE_THRESHOLD = 0.8  # Only auto-create if >80% confident
GUWU_LOG_MONITORING = True
GUWU_USE_AI_GENERATION = False  # Start with templates, enable AI later
```

---

## Success Metrics

**Phase 4 Successful When**:
1. âœ… Detects 90%+ of production bugs automatically
2. âœ… Generates correct tests with 80%+ accuracy
3. âœ… Reduces time-to-test from hours to minutes
4. âœ… Developer never has to manually write integration tests for bugs
5. âœ… Zero recurrence of similar bugs

---

## Risks & Mitigations

**Risk 1: False Positives** (generates wrong tests)
- Mitigation: Confidence scoring, require review for <80%

**Risk 2: Over-Generation** (creates too many tests)
- Mitigation: Only generate for actual failures, not all gaps

**Risk 3: Test Quality** (generated tests are poor quality)
- Mitigation: Learn from existing high-quality tests, use templates

**Risk 4: Performance** (log monitoring impacts app)
- Mitigation: Async processing, batch analysis

---

## Philosophy Alignment

**Gu Wu (é¡¾æ­¦)**: "Attending to martial affairs with discipline"

Phase 4 embodies this by:
- **Proactive Defense**: Prevents bugs before they happen
- **Continuous Learning**: Gets smarter with each failure
- **Autonomous Operation**: Requires no manual intervention
- **Martial Discipline**: Systematic, repeatable, reliable

---

## Next Steps (After Phase 3 Complete)

1. âœ… **Phase 3**: All tools autonomous (DONE - 2026-02-05)
2. ðŸ”œ **Phase 4.1**: Log monitoring integration (NEXT)
3. ðŸ”œ **Phase 4.2**: Failure pattern analysis
4. ðŸ”œ **Phase 4.3**: Test generation engine
5. ðŸ”œ **Phase 4.4**: Full integration & testing
6. ðŸ”œ **Phase 4.5**: Self-learning & refinement

**Target**: Phase 4 complete by Q2 2026

---

## Related Documents

- [[Gu Wu Testing Framework]] - Overview
- [[Gu Wu Phase 3 AI Capabilities]] - Current capabilities
- [[Comprehensive Testing Strategy]] - Testing philosophy
- [[Systematic Debugging Strategy]] - Debugging workflow

---

**Last Updated**: 2026-02-05  
**Status**: Design phase - awaiting Phase 3 completion  
**Owner**: Gu Wu Autonomous System